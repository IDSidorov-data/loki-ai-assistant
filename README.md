# LOKI - Локальный Голосовой AI-Ассистент

LOKI — это персонализированный голосовой AI-ассистент, спроектированный для работы полностью на локальном оборудовании. Он обеспечивает приватность и высокую скорость отклика, используя мощь локальных нейронных сетей для распознавания речи, генерации ответов и синтеза голоса.

Этот проект является результатом интенсивной отладки и оптимизации для достижения стабильной и производительной работы на потребительском оборудовании с AMD GPU под Windows.

## Ключевые Особенности

- **Полностью локальный:** Все компоненты (STT, LLM, TTS) работают на вашем ПК, не отправляя данные в облако.
- **Голосовая активация:** Реагирует на ключевое слово "Джарвис" (настраивается).
- **Высокая производительность:** Оптимизирован для быстрого ответа (2-4 секунды) за счет GPU-ускорения для LLM.
- **Качественная речь:** Использует точную модель Whisper `base` для распознавания и сверхбыстрый движок Piper для синтеза.
- **Визуальная обратная связь:** Интегрируется с Wallpaper Engine для отображения статуса ассистента (ожидание, прослушивание, речь).
- **Надежность:** Архитектура с разделением промптов минимизирует ошибки LLM и повышает точность выполнения команд.

## Технологический Стек

- **Активация по слову:** `pvporcupine`
- **Распознавание речи (STT):** `openai-whisper` (модель `base`) на CPU.
- **Языковая модель (LLM):** `Ollama` с `llama3:8b` с ускорением на GPU.
- **Синтез речи (TTS):** `piper-tts` на CPU.
- **Язык:** Python 3.11+
- **Управление зависимостями:** Poetry

## Архитектура и Принцип работы

LOKI построен по модульному принципу, где каждый компонент отвечает за свой этап обработки голосовой команды.

![Workflow Diagram](https://i.imgur.com/your-diagram-image.png)  <!-- Вы можете создать и вставить сюда диаграмму -->

**Основной цикл работы (Workflow):**

1.  **Ожидание (`idle`)**: `loki_core.py` с помощью `pvporcupine` постоянно слушает аудиопоток в ожидании ключевого слова "Джарвис". Визуально ассистент находится в состоянии покоя.
2.  **Прослушивание (`listening`)**: После активации `audio_handler.py` начинает запись голоса. Технология VAD (Voice Activity Detection) автоматически определяет, когда пользователь закончил говорить, и останавливает запись.
3.  **Распознавание (STT)**: Записанный аудиофайл передается в `stt_handler.py`, где модель `Whisper` преобразует речь в текст.
4.  **Мышление (LLM)**: Полученный текст отправляется в `llm_client.py` на обработку локальной языковой моделью через `Ollama`. В зависимости от содержания запроса, `loki_core.py` выбирает один из двух системных промптов из `prompts.py`:
    *   `DEFAULT_PROMPT`: Для обычных разговоров.
    *   `COMMAND_PROMPT`: Если в запросе есть ключевые слова команд ("статус", "режим"), чтобы получить ответ в строгом JSON-формате.
5.  **Парсинг и Выполнение**: Ответ от LLM обрабатывается в `command_parser.py`. Он разделяет текст для озвучки и JSON-команду.
    *   Если найдена команда (например, для смены статуса), `visual_controller.py` отправляет ее в Wallpaper Engine.
6.  **Ответ (`speaking`)**: Текстовая часть ответа передается в `tts_handler.py`, который с помощью `Piper` синтезирует речь и воспроизводит ее пользователю в потоковом режиме.
7.  **Возврат в режим ожидания**: После завершения ответа цикл возвращается к шагу 1.

## Установка и Запуск

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/IDSidorov-data/loki-ai-assistant
    cd loki-ai-assistant
    ```
2.  **Установите Poetry:**
    Инструкции по установке можно найти на [официальном сайте](https://python-poetry.org/docs/#installation). Убедитесь, что вы используете Python версии 3.11.

3.  **Установите зависимости:**
    Из корневой папки проекта выполните команду:
    ```bash
    poetry install
    ```
4.  **Настройте окружение:**
    - Создайте в корне проекта файл `.env` по примеру `.env.example` (если он есть) или с нуля.
    - Укажите в нем ваш `PICOVOICE_ACCESS_KEY`, полученный на [сайте Picovoice](https://console.picovoice.ai/).
    - Укажите полный путь к файлу голосовой модели Piper в `LOKI_PIPER_VOICE_PATH`. Готовые модели можно скачать [здесь](https://huggingface.co/rhasspy/piper-voices/tree/main).
    - При необходимости измените другие переменные.

5.  **Запустите сервер Ollama:**
    Убедитесь, что Ollama установлена и запущена. Выполните команду, чтобы скачать и подготовить модель:
    ```bash
    ollama pull llama3:8b-instruct-q4_k_m
    ```
    Для работы ассистента сервер Ollama должен быть запущен.

6.  **Запустите LOKI:**
    ```bash
    poetry run python loki/loki_core.py
    ```

## Кастомизация

- **Смена Wake Word**: Измените переменную `LOKI_WAKE_WORD` в `.env` на одно из стандартных слов (`alexa`, `computer`, `jarvis` и т.д.) или укажите путь к своему кастомному файлу `.ppn` через `LOKI_CUSTOM_WAKE_WORD_PATH`.
- **Смена голоса**: Скачайте другую модель голоса для Piper и укажите новый путь в `LOKI_PIPER_VOICE_PATH`.
- **Смена LLM**: Измените `OLLAMA_MODEL` в `.env` на любую другую модель, совместимую с Ollama.
- **Изменение личности**: Отредактируйте `DEFAULT_PROMPT` в `loki/prompts.py`, чтобы изменить стиль общения LOKI.