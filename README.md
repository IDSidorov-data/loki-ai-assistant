# LOKI - Локальный Голосовой AI-Ассистент

LOKI — это персонализированный голосовой AI-ассистент, спроектированный для работы полностью на локальном оборудовании. Он обеспечивает приватность и высокую скорость отклика, используя мощь локальных нейронных сетей для распознавания речи, генерации ответов и синтеза голоса.

Этот проект является результатом интенсивной отладки и оптимизации для достижения стабильной и производительной работы на потребительском оборудовании с AMD GPU под Windows.

## Ключевые Особенности

- **Полностью локальный:** Все компоненты (STT, LLM, TTS) работают на вашем ПК, не отправляя данные в облако.
- **Голосовая активация:** Реагирует на ключевое слово "Джарвис".
- **Высокая производительность:** Оптимизирован для быстрого ответа (2-4 секунды) за счет GPU-ускорения для LLM.
- **Качественная речь:** Использует точную модель Whisper `base` для распознавания и сверхбыстрый движок Piper для синтеза.
- **Стабильность:** Архитектура отлажена для обхода известных проблем совместимости с AMD GPU под Windows.

## Технологический Стек

- **Распознавание речи (STT):** `openai-whisper` (модель `base`) на CPU.
- **Языковая модель (LLM):** `Ollama` с `llama3:8b` с ускорением на GPU.
- **Синтез речи (TTS):** `piper-tts` на CPU.
- **Активация по слову:** `pvporcupine`.
- **Язык:** Python 3.11+

## Установка и Запуск

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/IDSidorov-data/loki-ai-assistant
    cd loki-ai-assistant
    ```
2.  **Установите зависимости:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Настройте окружение:**
    - Скопируйте `.env.example` в `.env`.
    - Укажите ваш `PICOVOICE_ACCESS_KEY`.
    - Укажите путь к модели голоса Piper.
4.  **Запустите сервер Ollama:**
    ```bash
    ollama serve
    ```
5.  **Запустите LOKI:**
    ```bash
    python loki/loki_core.py
    ```