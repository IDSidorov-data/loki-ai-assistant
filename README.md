# Проект LOKI: Локальный Голосовой Оркестратор

Проект LOKI — это локальная, автономная интеллектуальная система, предназначенная для управления состоянием через голосовые команды. Система использует Ollama для обработки естественного языка и Open-WebUI в качестве голосового шлюза.

## Архитектура

*   **Open-WebUI**: Принимает голосовой ввод (STT), отправляет текст в LLM и озвучивает ответ (TTS).
*   **Ollama**: Локальная LLM, исполняющая языковую модель.
*   **LOKI Orchestrator (Python)**: Ядро системы, которое:
    *   Опрашивает историю диалога через API Open-WebUI.
    *   Анализирует текст на наличие команд с помощью `command_parser`.
    *   Отправляет команды на `visual_server` для визуализации состояния.
*   **Visual Server**: Простой FastAPI сервер, имитирующий приемник команд (например, для Wallpaper Engine).

## Предварительные требования

1.  **Python 3.10+**
2.  **Git**: Для клонирования репозитория.
3.  **Docker Desktop**: Для запуска Open-WebUI.
4.  **Ollama**: Для локального запуска LLM. Скачать с [https://ollama.com/](https://ollama.com/).

## Развертывание

### Шаг 1: Настройка Внешних Компонентов (Ollama и Open-WebUI)

#### Ollama (Мозг)

1.  Установите Ollama с официального сайта.
2.  Скачайте языковую модель через терминал (рекомендуется `llama3:8b`):
    ```bash
    ollama pull llama3:8b
    ```
3.  Убедитесь, что Ollama работает в фоновом режиме.

#### Open-WebUI (Интерфейс)

1.  Убедитесь, что Docker Desktop запущен.
2.  **Важно:** Перед первым запуском рекомендуется удалить старые данные (если они есть), чтобы избежать конфликтов.
    ```bash
    docker volume rm open-webui
    ```
3.  Запустите контейнер Open-WebUI. Эта команда также связывает его с локальным Ollama.
    ```bash
    docker run -d -p 8080:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
    ```

### Шаг 2: Настройка Проекта LOKI

1.  Клонируйте репозиторий в удобное для вас место:
    ```bash
    git clone <repository_url>
    cd loki_project
    ```

2.  Создайте и активируйте виртуальное окружение:
    ```bash
    python -m venv venv
    ```
    *   **Windows:**
        ```bash
        .\venv\Scripts\activate
        ```
    *   **macOS / Linux:**
        ```bash
        source venv/bin/activate
        ```

3.  Установите зависимости Python:
    ```bash
    pip install -r requirements.txt
    pip install -e .
    ```
    *Примечание: `pip install -e .` устанавливает ваш проект в "режиме редактирования", что необходимо для корректной работы импортов между модулями.*

### Шаг 3: Настройка Токена Аутентификации

API Open-WebUI требует токен авторизации для всех запросов. Мы настроим его безопасным способом.

#### Часть А: Как найти токен

1.  Откройте Open-WebUI в браузере: `http://localhost:8080`.
2.  Нажмите **F12**, чтобы открыть Инструменты Разработчика, и перейдите на вкладку **"Сеть" (Network)**.
3.  Создайте аккаунт или войдите, а затем обновите страницу. В списке запросов найдите любой запрос к `/api/v1/...` (например, `chats`).
4.  Кликните на этот запрос, перейдите в раздел **"Заголовки" (Headers)** и найдите заголовок `Authorization`.
5.  Скопируйте значение токена — это длинная строка после `Bearer `.

#### Часть Б: Как безопасно сохранить токен

**Никогда не вставляйте токен напрямую в исходный код!** Вместо этого используйте переменные окружения.

1.  В **корневом каталоге** проекта (`loki_project`) создайте файл с именем `.env`.
2.  Откройте файл `.env` и добавьте в него ваш токен в следующем формате:
    ```
    LOKI_OLLAMA_TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOi..."
    ```
3.  *Примечание для разработчика: Код в `api_client.py` должен быть доработан для чтения этого токена из переменных окружения, например, с помощью библиотеки `python-dotenv` и `os.getenv('LOKI_OLLAMA_TOKEN')`.*

## Запуск Системы

Для работы системы необходимо запустить два компонента LOKI в отдельных терминалах (с активированным `venv`).

1.  **Запустите Visual Server (Терминал 1):**
    ```bash
    python loki/visual_server.py
    ```
    *Ожидаемый вывод: `INFO: Uvicorn running on http://127.0.0.1:8000`*

2.  **Запустите LOKI Core Orchestrator (Терминал 2):**
    ```bash
    python loki/loki_core.py
    ```
    *Ожидаемый вывод: `LOKI Core: Orchestrator is running. Waiting for commands...`*

## Использование

1.  Откройте интерфейс Open-WebUI (`http://localhost:8080`).
2.  Выберите модель (например, `llama3:8b`) и начните новый чат.
3.  Используя голосовой или текстовый ввод, произнесите команду, содержащую ключевую фразу.
4.  **Пример команды:** `"Локи, set status to processing"`
5.  Наблюдайте за логами в терминалах `loki_core` и `visual_server` для подтверждения получения и обработки команды.